"""
Conversation Summarization Module
Summarizes long chat histories to save tokens while preserving context.
"""

from __future__ import annotations

import logging
import os
from typing import Any

from google import genai
from google.genai import types

from ..data.constants import GEMINI_API_KEY

# Summarization Model (configurable via environment variable)
# Default to gemini-3-flash-preview for cost-effective summarization
SUMMARIZATION_MODEL = os.getenv("GEMINI_SUMMARIZATION_MODEL", "gemini-3-flash-preview")

# Conversation length thresholds
MIN_CONVERSATION_LENGTH = 200  # Minimum characters to summarize


# Summarization prompt template
SUMMARIZE_PROMPT = """à¸ªà¸£à¸¸à¸›à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸šà¹à¸¥à¸°à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ à¹ƒà¸™ 2-3 à¸›à¸£à¸°à¹‚à¸¢à¸„:
- à¹€à¸à¹‡à¸šà¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸ªà¸³à¸„à¸±à¸ à¸Šà¸·à¹ˆà¸­ à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸ˆà¸³
- à¹€à¸‚à¸µà¸¢à¸™à¹€à¸›à¹‡à¸™à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸šà¸¸à¸„à¸„à¸¥à¸—à¸µà¹ˆà¸ªà¸²à¸¡
- à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸šà¸—à¸ªà¸™à¸—à¸™à¸²

à¸šà¸—à¸ªà¸™à¸—à¸™à¸²:
{conversation}

à¸ªà¸£à¸¸à¸›:"""


class ConversationSummarizer:
    """Handles summarization of long conversations."""

    def __init__(self):
        self.client = None
        self.model = SUMMARIZATION_MODEL  # Configurable model for summarization

        if GEMINI_API_KEY:
            try:
                self.client = genai.Client(api_key=GEMINI_API_KEY)
            except Exception as e:
                logging.error("Failed to init Gemini Client for summarization: %s", e)

    async def summarize(self, history: list[dict[str, Any]], max_messages: int = 50) -> str | None:
        """Summarize conversation history.

        Args:
            history: List of message dicts with 'role' and 'parts'.
            max_messages: Max recent messages to summarize.

        Returns:
            Summary string or None if failed.
        """
        if not self.client or len(history) < 10:
            return None

        try:
            # Convert history to text
            conversation_text = self._history_to_text(history[-max_messages:])

            if len(conversation_text) < MIN_CONVERSATION_LENGTH:
                return None  # Too short to summarize

            # Generate summary
            prompt = SUMMARIZE_PROMPT.format(conversation=conversation_text)

            response = await self.client.aio.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    max_output_tokens=300,
                    temperature=0.3,  # Low temp for consistent summaries
                ),
            )

            summary = response.text.strip() if response.text else None

            if summary:
                logging.info("ðŸ“ Generated conversation summary: %s...", summary[:50])

            return summary

        except Exception as e:
            logging.error("Summarization failed: %s", e)
            return None

    def _history_to_text(self, history: list[dict[str, Any]]) -> str:
        """Convert history list to readable text."""
        lines = []
        for msg in history:
            role = "User" if msg.get("role") == "user" else "AI"
            parts = msg.get("parts", [])

            for part in parts:
                if isinstance(part, str):
                    # Truncate long messages
                    text = part[:500] + "..." if len(part) > 500 else part
                    lines.append(f"{role}: {text}")
                elif isinstance(part, dict) and "text" in part:
                    text = part["text"][:500] + "..." if len(part["text"]) > 500 else part["text"]
                    lines.append(f"{role}: {text}")

        return "\n".join(lines)

    async def should_summarize(self, history: list[dict[str, Any]], threshold: int = 100) -> bool:
        """Check if history should be summarized.

        Args:
            history: Current chat history.
            threshold: Number of messages before summarization.

        Returns:
            True if summarization is recommended.
        """
        return len(history) >= threshold

    async def compress_history(
        self, history: list[dict[str, Any]], keep_recent: int = 20
    ) -> list[dict[str, Any]]:
        """Compress history by summarizing old messages.

        Args:
            history: Full chat history.
            keep_recent: Number of recent messages to keep intact.

        Returns:
            Compressed history with summary + recent messages.
        """
        if len(history) <= keep_recent + 10:
            return history  # Not enough to compress

        # Split history
        old_history = history[:-keep_recent]
        recent_history = history[-keep_recent:]

        # Summarize old history
        summary = await self.summarize(old_history)

        if not summary:
            return history  # Keep original if summarization failed

        # Create compressed history
        summary_entry = {"role": "user", "parts": [f"[à¸šà¸—à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²]\n{summary}"]}

        compressed = [summary_entry, *recent_history]

        logging.info("ðŸ“¦ Compressed history: %d â†’ %d messages", len(history), len(compressed))

        return compressed


# Global instance
summarizer = ConversationSummarizer()
